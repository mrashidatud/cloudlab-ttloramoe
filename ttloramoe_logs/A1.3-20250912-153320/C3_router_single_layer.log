=== TTLoRA A1.3 â€“ C3 (router=single_layer) ===
git rev: b3c803f
experts: sst2 qqp mrpc cola winogrande_l rte
Fri Sep 12 15:33:25 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100S-PCIE-32GB          Off | 00000000:21:00.0 Off |                    0 |
| N/A   22C    P0              24W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100S-PCIE-32GB          Off | 00000000:E2:00.0 Off |                    0 |
| N/A   21C    P0              24W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
[RUN] python /local/TTLoRAMoE-SC25/Artifact_1.3/.moe_train_c3_20250912-153320.py --batchsize 32 --epochs 100 --patience 10 --workers 8 --gpus 2 --router single_layer --dataset sst2
/local/miniconda/lib/python3.13/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.3/.moe_train_c3_20250912-153320.py", line 8, in <module>
    runpy.run_path(os.path.join(os.path.dirname(__file__), 'moe_train.py'), run_name='__main__')
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 287, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/local/TTLoRAMoE-SC25/Artifact_1.3/moe_train.py", line 307, in <module>
    main()
    ~~~~^^
  File "/local/TTLoRAMoE-SC25/Artifact_1.3/moe_train.py", line 199, in main
    raise ValueError("The experts dictionary is empty. Please provide valid experts.")
ValueError: The experts dictionary is empty. Please provide valid experts.
