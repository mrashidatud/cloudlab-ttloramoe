=== TTLoRAMoE A1.2 single-dataset training (LoRA / TT-LoRA / Adapters) ===
Repo: /local/TTLoRAMoE-SC25
Env : ttloramoe (activation attempted; no installs)
GPUs: 2 (cap 4)  Workers: 8  Epochs: 100  Patience: 10
Batchsize: 32 (forced for all datasets)
Datasets: mrpc cola sst2 rte cb sick csqa winogrande_l cosmosqa socialiqa hellaswag qnli mnli

--- nvidia-smi ---
Wed Sep 10 08:31:33 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100S-PCIE-32GB          Off | 00000000:21:00.0 Off |                    0 |
| N/A   23C    P0              24W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100S-PCIE-32GB          Off | 00000000:E2:00.0 Off |                    0 |
| N/A   21C    P0              24W / 250W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+

--- git rev-parse (repo state) ---
b3c803f

[RUN] Adapter  dataset=mrpc  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (mrpc) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.86
----- END Adapter (mrpc) -----

[RUN] Adapter  dataset=cola  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (cola) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=4.99
----- END Adapter (cola) -----

[RUN] Adapter  dataset=sst2  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (sst2) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.03
----- END Adapter (sst2) -----

[RUN] Adapter  dataset=rte  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (rte) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.03
----- END Adapter (rte) -----

[RUN] Adapter  dataset=cb  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (cb) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.04
----- END Adapter (cb) -----

[RUN] Adapter  dataset=sick  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (sick) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=4.99
----- END Adapter (sick) -----

[RUN] Adapter  dataset=csqa  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (csqa) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.01
----- END Adapter (csqa) -----

[RUN] Adapter  dataset=winogrande_l  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (winogrande_l) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.03
----- END Adapter (winogrande_l) -----

[RUN] Adapter  dataset=cosmosqa  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (cosmosqa) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=4.98
----- END Adapter (cosmosqa) -----

[RUN] Adapter  dataset=socialiqa  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (socialiqa) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=4.99
----- END Adapter (socialiqa) -----

[RUN] Adapter  dataset=hellaswag  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (hellaswag) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=4.99
----- END Adapter (hellaswag) -----

[RUN] Adapter  dataset=qnli  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (qnli) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.04
----- END Adapter (qnli) -----

[RUN] Adapter  dataset=mnli  bs=32  gpus=2  workers=8  epochs=100  patience=10
----- BEGIN Adapter (mnli) -----
/local/miniconda/envs/ttloramoe/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/local/TTLoRAMoE-SC25/Artifact_1.2/single_Adapter_training.py", line 14, in <module>
    from adapters import AutoAdapterModel
ModuleNotFoundError: No module named 'adapters'
Command exited with non-zero status 1
WALL_SECONDS=5.03
----- END Adapter (mnli) -----

